import streamlit as st
import pandas as pd
from io import BytesIO
from typing import List, Optional, Tuple, Union
import unicodedata
import re

# --- Configuraci√≥n de la p√°gina ---
st.set_page_config(page_title="Consolidador Universal", page_icon="‚öôÔ∏è", layout="wide")

# --- Constantes ---
ENCODINGS = ['utf-8-sig', 'utf-8', 'latin1', 'windows-1252', 'iso-8859-1']
ILLEGAL_CHARACTERS_RE = re.compile(r"[\x00-\x08\x0B\x0C\x0E-\x1F\x7F-\x9F]")
CATEGORY_THRESHOLD = 0.5
DEFAULT_SHEET_NAME_INPUT = "0"


# --- Funciones Auxiliares ---

def limpiar_caracteres_ilegales(valor: any) -> any:
    """Elimina caracteres ilegales de un string."""
    if isinstance(valor, str): return ILLEGAL_CHARACTERS_RE.sub('', valor)
    return valor

def normalizar_nombre_columna(col: any) -> str:
    """Normaliza el nombre de una columna para que sea consistente y robusto."""
    if not isinstance(col, str): col = str(col)
    s = limpiar_caracteres_ilegales(col).lower().strip()
    s = ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')
    s = s.replace('¬∞', 'nro').replace('¬∫', 'nro')
    s = re.sub(r"[ ./\-]+", "_", s)
    s = re.sub(r'__+', '_', s)
    s = s.strip('_')
    return s if s else "columna_sin_nombre"

def optimizar_tipos_memoria(df: pd.DataFrame) -> pd.DataFrame:
    """Optimiza los tipos de datos de un DataFrame para reducir el uso de memoria."""
    df_optimizado = df.copy()
    for col in df_optimizado.select_dtypes(include=['float']).columns:
        df_optimizado[col] = pd.to_numeric(df_optimizado[col], downcast='integer')
    for col in df_optimizado.select_dtypes(include=['object']).columns:
        if col == 'archivo_origen': continue
        num_unicos = df_optimizado[col].nunique()
        if len(df_optimizado) > 0 and (num_unicos / len(df_optimizado)) < CATEGORY_THRESHOLD:
            df_optimizado[col] = df_optimizado[col].astype('category')
    return df_optimizado

# --- L√ìGICA DE LECTURA UNIVERSAL (LA CLAVE DE LA SOLUCI√ìN) ---
def leer_archivo(file, sheet_name: Union[str, int, None]) -> Optional[pd.DataFrame]:
    """
    Lee un archivo subido de forma inteligente, aplicando los par√°metros correctos
    seg√∫n la extensi√≥n del archivo.
    - 'sheet_name' solo se aplica a archivos Excel.
    - 'encoding' y 'sep' se aplican a archivos de texto.
    """
    nombre_archivo = file.name.lower()
    file.seek(0)
    
    try:
        # --- L√≥gica para archivos de Texto Plano ---
        if nombre_archivo.endswith(('.csv', '.txt', '.tsv')):
            sep = '\t' if nombre_archivo.endswith('.tsv') else ','
            for encoding in ENCODINGS:
                try:
                    file.seek(0)
                    return pd.read_csv(file, sep=sep, encoding=encoding, low_memory=False)
                except (UnicodeDecodeError, pd.errors.ParserError):
                    continue
            return None # Si ning√∫n encoding funcion√≥
        
        # --- L√≥gica para archivos Excel ---
        elif nombre_archivo.endswith(('.xlsx', '.xls')):
            engine = 'openpyxl' if nombre_archivo.endswith('.xlsx') else 'xlrd'
            return pd.read_excel(file, sheet_name=sheet_name, engine=engine)
            
    except Exception as e:
        st.error(f"Error cr√≠tico al leer '{file.name}': {e}")
        return None

    # Si la extensi√≥n no es soportada
    return None

def crear_excel_en_memoria(df: pd.DataFrame) -> BytesIO:
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='Consolidado')
    output.seek(0)
    return output

# --- Funci√≥n de Procesamiento Universal ---
def procesar_archivos(files: List, sheet_name: Union[str, int, None]) -> Tuple[Optional[pd.DataFrame], List[str]]:
    dataframes, logs = [], []
    
    # Comprobar si se ha usado una opci√≥n de hoja espec√≠fica
    sheet_option_used = str(sheet_name) != DEFAULT_SHEET_NAME_INPUT

    for file in files:
        logs.append(f"‚è≥ Procesando '{file.name}'...")

        # Notificar al usuario si la opci√≥n de hoja se ignora para archivos no-Excel
        is_excel = file.name.lower().endswith(('.xlsx', '.xls'))
        if sheet_option_used and not is_excel:
            logs.append(f"‚ÑπÔ∏è  Opci√≥n de hoja '{sheet_name}' ignorada para el archivo de texto '{file.name}'.")

        df = leer_archivo(file, sheet_name)
        
        if df is None:
            logs.append(f"üí• Error: No se pudo leer o decodificar el archivo '{file.name}'.")
            continue
        
        df.dropna(how='all', inplace=True)
        if df.empty:
            logs.append(f"‚ö†Ô∏è Aviso: El archivo '{file.name}' est√° vac√≠o o no contiene datos v√°lidos.")
            continue
        
        df.columns = [normalizar_nombre_columna(c) for c in df.columns]
        df = df.loc[:, ~df.columns.str.contains('^unnamed', na=False)]
        df['archivo_origen'] = file.name
        dataframes.append(df)
        logs.append(f"‚úÖ √âxito: '{file.name}' a√±adido a la consolidaci√≥n.")

    if not dataframes:
        return None, logs
    
    df_final = pd.concat(dataframes, ignore_index=True, sort=False)
    
    cols = df_final.columns.tolist()
    if 'archivo_origen' in cols:
        cols.insert(0, cols.pop(cols.index('archivo_origen')))
        df_final = df_final[cols]
    
    return optimizar_tipos_memoria(df_final), logs

# --- Interfaz Principal ---
def main():
    st.title("‚öôÔ∏è Consolidador Universal de Archivos")
    st.markdown(
        "Sube m√∫ltiples archivos (`Excel`, `CSV`, `TXT`, `TSV`). El sistema los procesar√° "
        "de forma inteligente y unir√° todas sus columnas en un √∫nico resultado."
    )
    
    with st.expander("Opciones avanzadas"):
        sheet_input = st.text_input(
            "Nombre u hoja de Excel a leer (solo para .xlsx/.xls)", 
            DEFAULT_SHEET_NAME_INPUT,
            help="Escribe el nombre de la hoja (ej. 'Ventas') o el n√∫mero (empezando en 0)."
        )
        try: sheet_name = int(sheet_input)
        except ValueError: sheet_name = sheet_input
            
    archivos = st.file_uploader(
        "üì§ Sube tus archivos aqu√≠",
        type=['xlsx', 'xls', 'csv', 'txt', 'tsv'],
        accept_multiple_files=True
    )

    if archivos:
        with st.spinner("üîÑ Procesando y consolidando archivos..."):
            df_consolidado, logs = procesar_archivos(archivos, sheet_name)

        st.subheader("üìú Registro de Procesamiento")
        for log in logs:
            if "‚úÖ" in log: st.success(log)
            elif "‚ö†Ô∏è" in log: st.warning(log)
            elif "üí•" in log: st.error(log)
            else: st.info(log)
        
        st.markdown("---")

        if df_consolidado is not None and not df_consolidado.empty:
            st.header("üéâ Consolidaci√≥n completada")
            st.success(f"Se han consolidado **{df_consolidado.shape[0]:,}** filas y **{df_consolidado.shape[1]}** columnas.")
            
            st.subheader("üìä Previsualizaci√≥n (primeros 500 registros)")
            st.dataframe(df_consolidado.head(500).astype(str), use_container_width=True)

            st.subheader("‚¨áÔ∏è Descarga")
            try:
                with st.spinner("‚è≥ Preparando archivo Excel (puede tardar con archivos muy grandes)..."):
                    excel_bytes = crear_excel_en_memoria(df_consolidado)
                st.success("‚úÖ ¬°Archivo Excel listo!")
                st.download_button("üì• Descargar Excel Consolidado (.xlsx)", excel_bytes, "consolidado.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", use_container_width=True)
            except Exception as e:
                st.error(f"üí• **Error al generar Excel:** {e}")
                st.info("**Plan B:** Descargando como CSV, un formato m√°s r√°pido y fiable para archivos grandes.")
                with st.spinner("‚è≥ Generando archivo CSV de respaldo..."):
                    csv_bytes = df_consolidado.to_csv(index=False).encode('utf-8-sig')
                st.download_button("üì• Descargar Datos en CSV (.csv)", csv_bytes, "consolidado.csv", "text/csv", use_container_width=True)
        else:
            st.error("‚ùå No se pudo generar un archivo consolidado. Revisa los registros.")
    else:
        st.info("A la espera de archivos para iniciar el proceso de consolidaci√≥n.")

if __name__ == "__main__":
    main()
